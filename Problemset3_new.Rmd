---
title: "Toronto's Underpriviledged Neighbourhoods are Close to Each Other"
author: "Ke-Li Chiu & Diego Mamanche Castellanos"
date: "29/02/2020"
output:
  pdf_document: default
  html_document: default
abstract: Abstract nnnnn nnnnnn
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, echo=FALSE, include=FALSE}
# Importing libraries
library(opendatatoronto)
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)
library(sf)
library(tmap)
library(tmaptools)
library(leaflet)
library(corrplot) #For correlation matrix
library(car)
library(dbscan) # For density-based model
library(fpc) # For dessity-based model
library(factoextra)
```

```{r include=FALSE}
#setwd("~/Desktop/MI/INF2178 Experienment DS/Problem set 3")
# Get the resource we want from this package
neighbourhood_raw <- list_package_resources("6e19a90f-971c-46b3-852c-0c48c436d1fc") %>% 
  filter(name == "neighbourhood-profiles-2016-csv") %>% 
  get_resource()
main_df_raw <- neighbourhood_raw
main_df_raw <- as.data.frame(main_df_raw)
# Remove "X2011 prefix from all column names"
```
```{r include=FALSE}
### GEO-LOCATION DATASET TORONTO BY NEIGHBOURHOODS ###
# get package
package <- show_package("4def3f65-2a65-4a4f-83c4-b2a4aed72d46")
package
# get all resources for this package
resources <- list_package_resources("4def3f65-2a65-4a4f-83c4-b2a4aed72d46")
# identify datastore resources; by default, Toronto Open Data sets datastore resource format to CSV for non-geospatial and GeoJSON for geospatial resources
datastore_resources <- filter(resources, tolower(format) %in% c('csv', 'geojson'))
# load the first datastore resource as a sample
geo_data <- filter(datastore_resources, row_number()==1) %>% get_resource()
### Cleaning geo-location dataset
clean_geo_data <- janitor::clean_names(geo_data)
clean_geo_data <- extract(clean_geo_data, area_name, into = "neighbourhoods" , regex = "([^(0-9)]+)")
clean_geo_data["neighbourhoods"] <- 
  janitor::make_clean_names(as.matrix(clean_geo_data["neighbourhoods"]))
clean_geo_data <- janitor::clean_names(clean_geo_data)
clean_geo_data <- select(clean_geo_data, neighbourhoods, longitude, latitude, geometry)
filter(clean_geo_data, neighbourhoods %in% c("mimico","weston_pellam_park"))
clean_geo_data["neighbourhoods"][c(17,67),] <- c("mimico_includes_humber_bay_shores","weston_pelham_park")
clean_geo_data
```

```{r echo=FALSE, include=FALSE}
#Save neighbourhoods into a dataframe
col_names_2011 <- as.data.frame(colnames(main_df_raw))
col_names_2011 <- col_names_2011[7:nrow(col_names_2011),]
col_names_2011 <- as.data.frame(col_names_2011)
colnames(col_names_2011) <- "neighbourhoods"
#Filter education per neighbourhood
main_df <- filter(main_df_raw, 
                      Category == "Neighbourhood Information" | 
                      Category == "Income" | 
                      Characteristic == "Population, 2016" | 
                      Characteristic == "Rate of unsuitable housing"|
                      Topic == "Visible minority population" | 
                      Topic == "Highest certificate, diploma or degree" |
                      Topic == "Low income in 2015")
```

```{r echo= FALSE, include = FALSE}
# Reshape the dataframe (swap row and columns)
main_df_reshaped <- data.frame(t(main_df[-1]))
colnames(main_df_reshaped) <- main_df[, 1]
# Slice the reshaped dataframe
main_df_sliced <- main_df_reshaped %>%
  dplyr::slice(4:nrow(main_df_reshaped))
# Turn characteristics to column names
names(main_df_sliced) <- as.matrix(main_df_sliced[1, ])
main_df_sliced <- main_df_sliced[-1, ]
main_df_sliced[] <- lapply(main_df_sliced, function(x) type.convert(as.character(x)))
# Clean column names
library(janitor)
main_df_sliced <- main_df_sliced %>% clean_names()
main_df_sliced$total_population_aged_15_years_and_over_by_major_field_of_study_classification_of_instructional_programs_cip_2011
main_df_sliced$x18_to_64_years_percent
main_df_sliced = main_df_sliced[-1,]
main_df_sliced <- mutate(main_df_sliced, neighbourhoods = col_names_2011$neighbourhoods)
# Assign 0 as Toronto neighbourhood number
main_df_sliced$neighbourhood_number <- as.numeric(as.character(main_df_sliced$neighbourhood_number)) 
main_df_sliced$neighbourhood_number[is.na(main_df_sliced$neighbourhood_number)] <- 0 
main_df_sliced$neighbourhood_number <- as.factor(main_df_sliced$neighbourhood_number)
```
```{r echo= FALSE, include=FALSE}
# Select wanted columns to make a new dataframe
df_cleaned <- main_df_sliced %>%
  select(
    "neighbourhood_number",
    "neighbourhoods",
    "population_2016",
    "total_highest_certificate_diploma_or_degree_for_the_population_aged_25_to_64_years_in_private_households_25_percent_sample_data",
    
    # education
    "no_certificate_diploma_or_degree_2",
    # low income percentage
    "x18_to_64_years_percent",
    
    # visible minority
    "total_visible_minority_population"
  )
# transform df to numeric
df_cleaned$population_2016 = as.numeric(gsub(",", "", df_cleaned$population_2016))
df_cleaned$total_visible_minority_population = as.numeric(gsub(",", "", df_cleaned$total_visible_minority_population))
df_cleaned
```

``` {r echo= FALSE, include=FALSE}
## Turn absolute values to percentage
total_population_education <- df_cleaned$total_highest_certificate_diploma_or_degree_for_the_population_aged_25_to_64_years_in_private_households_25_percent_sample_data
# Education data transformation
df_cleaned <- 
  mutate(df_cleaned, no_certificate_diploma_or_degree_2 =
           (df_cleaned$no_certificate_diploma_or_degree_2/total_population_education)*100)
# Visible miniority data transformation
df_cleaned <- 
  mutate(df_cleaned, total_visible_minority_population =
           (df_cleaned$total_visible_minority_population/df_cleaned$population_2016)*100)
df_cleaned
  
###draw correlation matrix of the numeric independent variables only
num_data <- df_cleaned[,-c(1:2)] ### only numeric independent vars
colnames(num_data) <- c("population","total_highest_cert","no_certificate","18_to_64_per","visible_minority")
correlationMatrix <- cor(num_data, method = "pearson") 
correlationMatrix    # a 6x6 matrix   
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(correlationMatrix, method="color", col=col(200),   
         type="upper", order="hclust", 
         tl.col="black", tl.srt=45, tl.cex= 0.7, #Text label color and rotation
         # Combine with significance
         sig.level = 0.01, 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE
)
```

```{r echo= FALSE, include=FALSE}
# Normalize data by subtracting the mean and dividing it by the standard deviation.
df_selected_columns = df_cleaned[,c(
  # Education
   "no_certificate_diploma_or_degree_2",
  # Low income
   "x18_to_64_years_percent", # low income
  
  # Visible minority
   "total_visible_minority_population"
  )]
means = apply(df_selected_columns,2,mean)
sds = apply(df_selected_columns,2,sd)
nor = scale(df_selected_columns,means,sds)
nor
###draw correlation matrix of the numeric variables only
num_data <- as.data.frame(nor) ### only numeric independent vars
colnames(num_data) <- c("no_certificate","18_to_64_per","visible_minority")
correlationMatrix <- cor(num_data, method = "pearson") 
correlationMatrix    # a 6x6 matrix   
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
corrplot(correlationMatrix, method="color", col=col(200),   
         type="upper", order="hclust", 
         tl.col="black", tl.srt=45, tl.cex= 0.7, #Text label color and rotation
         # Combine with significance
         sig.level = 0.01, 
         # hide correlation coefficient on the principal diagonal
         diag=FALSE
)
```
# Introduction
There are 140 neighbourhoods officially recognized by the City of Toronto and the divisions are used for internal planning purposes. Many shorcomings of economic or social policy planning and making come from the over-reliance on “one-size-fits-all” approach that overlooks their differences in socioeconomic status. However, customizing policies for 140 neighbourhoods is also improbable. Can we then create groups of neighbourhoods that share similar socioeconomic traits so policy makers can plan strategically and efficiently? Can we identify the group of neighbourhoods that are vulnerable in their social and economic development so they receive more attention from the Government? In this study, a clustering analysis is conducted to be used to define neighborhood types and display their characteristics and spatial patterns.

Troubling differences in poverty, education and diversity exist among neighbourhoods in the City of Toronto. According to David Hulchanski, a professor of the University of Toronto who uses the 2016 census to create demographic charts of Toronto, the city is segregated by race and income. For example, visible minorities are concentrated in low-income neighbourhoods and white residents are dominating affluent areas in numbers far higher than their share of the population. The segregation pointed out by Hulchanski leads to our choices of traits we use to conduct the clustering analysis for the neighbourhoods — low-income rate, population percentage of residents who have no education certificate, and visible minority population percentage. We intend to then articulate the social stratification and spatial stratification in the City of Toronto.

# Dataset and Method Description

## Limitation of the Dataset and Approach
In 2016, the long form Census became mandatory once again, and was distributed to one out of every four households (25%). Income data were gathered solely by linking with administrative data (Canada Revenue Agency). Census data is subject to error such as coverage, non-response, and sampling errors. Moreover, althought the Census is mandatory, it is still likely to be affected by Response Bias because people do not always provide accurate or truthful information. This is especially common in collection of income data. Correct income data are often more difficult to obtain because the richest households are more prompted to underreport their incomes. Therefore, the income inequality based on data from household surveys are likely to be underestimated.

Another limitation lies in the lack of time-series data to be compared with the data sourced from 2016. This prevents a holistic observation in the change of socioeconomic dynamic in the neighbourhoods across time. The neghbourhoods may not be assigned to the same clusters based on data sourced from past years. Such shifts would provide insights that is not available in this study.

## Ethical Considerations
Features such as race or income can be highly predictive for certain problems. The three variables in poverty, education, and visible minority population in this clustering analysis does not provide details of underlying contributors for the social division in the neighbourhoods. Without further investigation, the study possibley shapes the categories of perception and classification through which readers internalize social divisions. These categories shape the way we envision class structure and social problems associated with the neighbourhoods and paved the way for implicit stigmatization. More crucially, the incorporation of these categories structures decisions to buy property and, for parents, to send children to the local schools.

# Hierarchical Clustering of Toronto's Neighbourhoods

## Calculating distance between observations (Neighbourhoods)
Firstly, Euclidean Distance Between Toronto's Neighbourhoods is calculated and used to construct a dendrogram. The height of the branch points indicates how similar or different the neighbourhoods are from each other; the greater the height, the greater the difference. 

```{r echo=FALSE}
# Get the distance of the normalized data
distance = dist(nor)
plot_data <- nor
# Hierarchical agglomerative clustering using default complete linkage 
plot_data_comp = hclust(distance)
plot(plot_data_comp,labels=plot_data_comp$ID,main='Default from hclust', cex=.4)
```

## Determine optimal number of clusters

The Elbow Method is used to determine the optimal number of clusters. Viewing the Scree Plot (Figure X), the "elbow" on the arm is "2" on the x-axis. Therefore, the neighbourhoods will be assigned to two different clusters.

```{r echo=FALSE}
# Scree Plot
wss <- (nrow(nor)-1)*sum(apply(nor,2,var))
for (i in 2:20) wss[i] <- sum(kmeans(nor, centers=i)$withinss)
plot(1:20, wss, type="b", xlab="Number of Clusters", ylab="Within groups sum of squares")
```

## Assessing Characteristics of Neighbourhood Clusters
The two clusters has different numbers of members. In Group 1, there are 34 neighbourhoods while the other 106 are assigned to Group 2. Table x. showcases the distances between the means of the two clusters with normalized data values. The distinction between the two clusters is clear—all values in Group 1 are positive and all values in Group 2 are all negative. The positive values in Group 1 indicates its characteristics in higher percentage in poverty, lack of education and visibile minority population.

``` {r echo=FALSE}
# Characterizing clusters 
member = cutree(plot_data_comp,2)
table(member)
member_df <- as.data.frame(member)
variables_df <- aggregate(nor,list(member),mean)
variables_df
```
```{r echo=FALSE, include=FALSE}
plot(plot_data_comp,hang=-1, cex=.4)
rect.hclust(plot_data_comp, k = 2, border = "red")
```

## Clusters Distribution
The grouped scattor plots shows that there is a pattern of neighbourhood distribution within the three selected variables. In general, the 34 neighbourhoods in Group 1 are located at the top-right area of the graphs, which visualizes its characteristics in higher percentage in poverty, lack of education and visibile minority population.

```{r echo=FALSE}
#get hclust label to neighbourhoods
hcluster <- cutree(plot_data_comp, k=2)
hcluster <- as.data.frame(hcluster)
df_w_vector <- mutate(df_cleaned, hcluster = hcluster$hcluster)
#merge dataset with geo dataset
df_w_vector["neighbourhoods"] <- 
  janitor::make_clean_names(as.matrix(df_w_vector["neighbourhoods"]))
merged_df <- merge(df_w_vector, clean_geo_data, by = 'neighbourhoods')
merged_df$hcluster <- as.factor(merged_df$hcluster)
sf_merged_df <- st_sf(merged_df, sf_column_name = "geometry")
colors <- c("#00AFBB", "#E7B800", "#FC4E07", "#000000")
colors <- colors[merged_df$hcluster]
plot(df_selected_columns, col = colors)
par(xpd=TRUE)
legend(legend = unique(merged_df$hcluster), col =unique(colors), pch = 19, bty = "o", "bottomright", cex = .8)
# how to label the clusters
# label the data entries(cluster number)
# going back from distrance to real values
```

## Toronto's Neighbourhoods Clusters Map

Through the visualization of a map, we can see that the neighbourhoods in Group 1 not only share similar socieconomic traits, they are also geographically close to each other. The geographic proximity of the vulnerable neighbourhoods [to be continued...] 

```{r echo=FALSE}
#Plot all majors without palette
tmap_mode("plot")
tm_shape(sf_merged_df) +
tm_layout(legend.show = TRUE, legend.position = c("right", "bottom"), title.size = 2, title.position = c("center","center")) +
  tm_polygons(c("hcluster"), style = "pretty") +
  tm_text("neighbourhood_number", auto.placement = TRUE, xmod = 0, size = 0.3)+
  tm_facets(sync = TRUE, ncol = 1)
```


```{r}
set.seed(123)
km.res <- kmeans(num_data, 2, nstart = 25)
fviz_cluster(km.res, num_data,  geom = "point", 
             ellipse= FALSE, show.clust.cent = FALSE,
             palette = "jco", ggtheme = theme_classic())
dbscan::kNNdistplot(num_data, k =  3)
abline(h = .95, lty = 2)
pred_dbscan <- fpc::dbscan(num_data, .95, 5)
pred_dbscan
fviz_cluster(pred_dbscan, num_data, geom = "point")
?kNN
```

To be included in references:
https://www.justice.gc.ca/eng/rp-pr/cj-jp/yj-jj/yj1-jj1/p1_6.html
https://www23.statcan.gc.ca/imdb/p2SV.pl?Function=getSurvey&SDDS=3901
https://www.datanovia.com/en/lessons/dbscan-density-based-clustering-essentials/